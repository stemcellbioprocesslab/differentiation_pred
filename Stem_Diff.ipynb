{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea52222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a function to extract bubble features from an image\n",
    "def extract_bubble_features(image_path, min_bubble_area=10, max_bubble_area=1000):\n",
    "    # Load and preprocess the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Apply bubble segmentation to extract the number of bubbles as a feature\n",
    "    def segment_bubbles(image):\n",
    "        # Apply adaptive histogram equalization\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(1, 1))\n",
    "        equalized_image = clahe.apply(image)\n",
    "\n",
    "        # Apply adaptive thresholding to segment bubbles\n",
    "        block_size = 91\n",
    "        thresholded = cv2.adaptiveThreshold(equalized_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, 2)\n",
    "\n",
    "        # Find connected components and filter out small and large regions (bubbles)\n",
    "        num_labels, labeled_image = cv2.connectedComponents(thresholded)\n",
    "        bubble_areas = []  # To store areas of bubbles\n",
    "        for label in range(1, num_labels):\n",
    "            label_mask = np.uint8(labeled_image == label)\n",
    "            label_area = np.sum(label_mask)\n",
    "            if min_bubble_area < label_area < max_bubble_area:\n",
    "                bubble_areas.append(label_area)\n",
    "        return len(bubble_areas), sum(bubble_areas), image.shape[0] * image.shape[1]  # Return the number of bubbles, total area, and image area\n",
    "    \n",
    "    num_bubbles, total_area, image_area = segment_bubbles(image)\n",
    "    \n",
    "    # Calculate the percentage area covered by bubbles\n",
    "    percentage_area_covered = (total_area / image_area) * 100\n",
    "    \n",
    "    # Calculate the uniformity of distribution\n",
    "    uniformity = num_bubbles / (image_area / 10000)  # Normalize by dividing by 10,000\n",
    "    \n",
    "    # Calculate the mean size of bubbles\n",
    "    mean_bubble_size = total_area / num_bubbles\n",
    "    \n",
    "    return num_bubbles, total_area, percentage_area_covered, uniformity, mean_bubble_size\n",
    "\n",
    "# Specify the path to your dataset folders\n",
    "positive_class_folder = \"./Good_New_4X\"\n",
    "negative_class_folder = \"./Bad_New_4X\"\n",
    "\n",
    "# Collect the paths to all images in the dataset\n",
    "positive_class_images = [os.path.join(positive_class_folder, filename) for filename in os.listdir(positive_class_folder)]\n",
    "negative_class_images = [os.path.join(negative_class_folder, filename) for filename in os.listdir(negative_class_folder)]\n",
    "\n",
    "# Create lists to store features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Extract features and labels from positive class images\n",
    "for image_path in positive_class_images:\n",
    "    num_bubbles, total_area, percentage_area_covered, uniformity, mean_bubble_size = extract_bubble_features(image_path)\n",
    "    features.append([num_bubbles, total_area, percentage_area_covered, uniformity, mean_bubble_size])\n",
    "    labels.append(1)  # Positive class\n",
    "\n",
    "# Extract features and labels from negative class images\n",
    "for image_path in negative_class_images:\n",
    "    num_bubbles, total_area, percentage_area_covered, uniformity, mean_bubble_size = extract_bubble_features(image_path)\n",
    "    features.append([num_bubbles, total_area, percentage_area_covered, uniformity, mean_bubble_size])\n",
    "    labels.append(0)  # Negative class\n",
    "\n",
    "# Convert the features list to a 2D array\n",
    "X = np.array(features)\n",
    "\n",
    "# Save the extracted features and labels to a file\n",
    "np.save('extracted_features_New_4X.npy', X)\n",
    "np.save('labels_New_4X.npy', labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b698174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your features and labels\n",
    "loaded_features = np.load('extracted_features_New_4X.npy')\n",
    "loaded_labels = np.load('labels_New_4X.npy')\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the loaded features\n",
    "loaded_features = scaler.fit_transform(loaded_features)\n",
    "\n",
    "# Initialize arrays to store the metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_score_list = []\n",
    "roc_auc_list = []\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]\n",
    "}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(probability=True)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(svm, param_grid, scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "# Perform GridSearchCV and calculate metrics\n",
    "grid_search.fit(loaded_features, loaded_labels)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(\"C:\", best_model.C)\n",
    "print(\"Kernel:\", best_model.kernel)\n",
    "print(\"Gamma:\", best_model.gamma)\n",
    "\n",
    "# Stratified Cross-Validation\n",
    "stratified_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Stratified Cross-Validation and calculate metrics\n",
    "for i, (train_index, test_index) in enumerate(stratified_kf.split(loaded_features, loaded_labels)):\n",
    "    X_train, X_test = loaded_features[train_index], loaded_features[test_index]\n",
    "    y_train, y_test = loaded_labels[train_index], loaded_labels[test_index]\n",
    "\n",
    "    # Train the best model on the training data\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]  # Probability of belonging to the positive class\n",
    "\n",
    "    # Calculate and store accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "    # Calculate and store precision, recall, F1 score, and ROC-AUC score\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_score_list.append(f1)\n",
    "    roc_auc_list.append(roc_auc)\n",
    "\n",
    "# Calculate and print average metrics\n",
    "average_accuracy = np.mean(accuracy_list)\n",
    "average_precision = np.mean(precision_list)\n",
    "average_recall = np.mean(recall_list)\n",
    "average_f1_score = np.mean(f1_score_list)\n",
    "average_roc_auc = np.mean(roc_auc_list)\n",
    "\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "print(\"Average Precision:\", average_precision)\n",
    "print(\"Average Recall:\", average_recall)\n",
    "print(\"Average F1 Score:\", average_f1_score)\n",
    "print(\"Average ROC-AUC Score:\", average_roc_auc)\n",
    "\n",
    "# Export metrics to an Excel file\n",
    "metrics_dict = {\n",
    "    \"Fold\": list(range(1, stratified_kf.n_splits + 1)),\n",
    "    \"Accuracy\": accuracy_list,\n",
    "    \"Precision\": precision_list,\n",
    "    \"Recall\": recall_list,\n",
    "    \"F1 Score\": f1_score_list,\n",
    "    \"ROC-AUC Score\": roc_auc_list,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(metrics_dict)\n",
    "df.to_excel(\"svm_metrics_hyperparameter_tuning_new4X.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE\n",
    "\n",
    "# Load your features and labels\n",
    "features_path = './extracted_features_New_4X.npy'\n",
    "labels_path = './labels_New_4X.npy'\n",
    "\n",
    "loaded_features = np.load(features_path)\n",
    "loaded_labels = np.load(labels_path)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the loaded features\n",
    "loaded_features = scaler.fit_transform(loaded_features)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "model = SVC(kernel='sigmoid', probability=True, C = 1, gamma = 1 )\n",
    "\n",
    "# Initialize arrays to store metrics for each fold\n",
    "cv_accuracies = []\n",
    "cv_precisions = []\n",
    "cv_recalls = []\n",
    "cv_f1_scores = []\n",
    "cv_roc_auc_scores = []\n",
    "\n",
    "# Initialize an array to store the average model coefficients\n",
    "#average_model_coefficients = np.zeros(loaded_features.shape[1])\n",
    "\n",
    "# Stratified Cross-Validation\n",
    "stratified_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Stratified Cross-Validation and calculate metrics\n",
    "for fold, (train_index, test_index) in enumerate(stratified_kf.split(loaded_features, loaded_labels), 1):\n",
    "    X_train, X_test = loaded_features[train_index], loaded_features[test_index]\n",
    "    y_train, y_test = loaded_labels[train_index], loaded_labels[test_index]\n",
    "\n",
    "    # Apply SMOTE to balance the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Print the number of instances for each class in each fold after SMOTE for training set\n",
    "    print(f\"\\nFold {fold} - Training Set (After SMOTE):\")\n",
    "    print(\"Positive Class Instances:\", np.sum(y_train_smote == 1))\n",
    "    print(\"Negative Class Instances:\", np.sum(y_train_smote == 0))\n",
    "\n",
    "    # Train the SVM model on the balanced training data\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Get the coefficients of the support vectors\n",
    "    #coefficients = model.coef_[0]\n",
    "\n",
    "    # Accumulate the coefficients for this fold\n",
    "    #average_model_coefficients += coefficients\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    cv_accuracies.append(accuracy)\n",
    "    cv_precisions.append(precision)\n",
    "    cv_recalls.append(recall)\n",
    "    cv_f1_scores.append(f1)\n",
    "    cv_roc_auc_scores.append(roc_auc)\n",
    "\n",
    "    # Print the number of instances for each class in each fold after SMOTE for testing set\n",
    "    print(f\"\\nFold {fold} - Testing Set (After SMOTE):\")\n",
    "    print(\"Positive Class Instances:\", np.sum(y_test == 1))\n",
    "    print(\"Negative Class Instances:\", np.sum(y_test == 0))\n",
    "\n",
    "# Calculate the average coefficients over all folds\n",
    "#average_model_coefficients /= stratified_kf.n_splits\n",
    "\n",
    "# Print the average coefficients\n",
    "print(\"\\nAverage Model Coefficients:\")\n",
    "#for i, coef in enumerate(average_model_coefficients):\n",
    "#    print(f\"Feature {i+1}: {coef}\")\n",
    "\n",
    "# Print the average metrics over all folds\n",
    "print(\"\\nAverage Metrics:\")\n",
    "print(f\"Average Accuracy: {np.mean(cv_accuracies)}\")\n",
    "print(f\"Average Precision: {np.mean(cv_precisions)}\")\n",
    "print(f\"Average Recall: {np.mean(cv_recalls)}\")\n",
    "print(f\"Average F1 Score: {np.mean(cv_f1_scores)}\")\n",
    "print(f\"Average ROC-AUC: {np.mean(cv_roc_auc_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a function to extract bubble features from an image\n",
    "def extract_bubble_features(image_path, min_bubble_area=10, max_bubble_area=1000):\n",
    "    # Load and preprocess the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Apply bubble segmentation to extract the number of bubbles as a feature\n",
    "    def segment_bubbles(image):\n",
    "        # Apply adaptive histogram equalization\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(1, 1))\n",
    "        equalized_image = clahe.apply(image)\n",
    "\n",
    "        # Apply adaptive thresholding to segment bubbles\n",
    "        block_size = 91\n",
    "        thresholded = cv2.adaptiveThreshold(equalized_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, 2)\n",
    "\n",
    "        # Find connected components and filter out small and large regions (bubbles)\n",
    "        num_labels, labeled_image = cv2.connectedComponents(thresholded)\n",
    "        bubble_areas = []  # To store areas of bubbles\n",
    "        for label in range(1, num_labels):\n",
    "            label_mask = np.uint8(labeled_image == label)\n",
    "            label_area = np.sum(label_mask)\n",
    "            if min_bubble_area < label_area < max_bubble_area:\n",
    "                bubble_areas.append(label_area)\n",
    "        return len(bubble_areas), sum(bubble_areas), image.shape[0] * image.shape[1]  # Return the number of bubbles, total area, and image area\n",
    "    \n",
    "    num_bubbles, total_area, image_area = segment_bubbles(image)\n",
    "    \n",
    "    # Calculate the percentage area covered by bubbles\n",
    "    percentage_area_covered = (total_area / image_area) * 100\n",
    "    \n",
    "    # Calculate the uniformity of distribution\n",
    "    uniformity = num_bubbles / (image_area / 10000)  # Normalize by dividing by 10,000\n",
    "    \n",
    "    # Calculate the mean size of bubbles\n",
    "    mean_bubble_size = total_area / num_bubbles\n",
    "    \n",
    "    return num_bubbles, total_area, percentage_area_covered, uniformity, mean_bubble_size\n",
    "\n",
    "# Specify the path to your dataset folders\n",
    "positive_class_folder = \"./Good_New_10X\"\n",
    "negative_class_folder = \"./Bad_New_10X\"\n",
    "\n",
    "# Collect the paths to all images in the dataset\n",
    "positive_class_images = [os.path.join(positive_class_folder, filename) for filename in os.listdir(positive_class_folder)]\n",
    "negative_class_images = [os.path.join(negative_class_folder, filename) for filename in os.listdir(negative_class_folder)]\n",
    "\n",
    "# Create lists to store features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Extract features and labels from positive class images\n",
    "for image_path in positive_class_images:\n",
    "    num_bubbles, total_area, percentage_area_covered, uniformity, mean_bubble_size = extract_bubble_features(image_path)\n",
    "    features.append([num_bubbles, total_area, percentage_area_covered, uniformity, mean_bubble_size])\n",
    "    labels.append(1)  # Positive class\n",
    "\n",
    "# Extract features and labels from negative class images\n",
    "for image_path in negative_class_images:\n",
    "    num_bubbles, total_area, percentage_area_covered, uniformity, mean_bubble_size = extract_bubble_features(image_path)\n",
    "    features.append([num_bubbles, total_area, percentage_area_covered, uniformity, mean_bubble_size])\n",
    "    labels.append(0)  # Negative class\n",
    "\n",
    "# Convert the features list to a 2D array\n",
    "X = np.array(features)\n",
    "\n",
    "# Save the extracted features and labels to a file\n",
    "np.save('extracted_features_New_10X.npy', X)\n",
    "np.save('labels_New_10X.npy', labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af32dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your features and labels\n",
    "loaded_features = np.load('extracted_features_New_10X.npy')\n",
    "loaded_labels = np.load('labels_New_10X.npy')\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the loaded features\n",
    "loaded_features = scaler.fit_transform(loaded_features)\n",
    "\n",
    "# Initialize arrays to store the metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_score_list = []\n",
    "roc_auc_list = []\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]\n",
    "}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(probability=True)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(svm, param_grid, scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "# Perform GridSearchCV and calculate metrics\n",
    "grid_search.fit(loaded_features, loaded_labels)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(\"C:\", best_model.C)\n",
    "print(\"Kernel:\", best_model.kernel)\n",
    "print(\"Gamma:\", best_model.gamma)\n",
    "\n",
    "# Stratified Cross-Validation\n",
    "stratified_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Stratified Cross-Validation and calculate metrics\n",
    "for i, (train_index, test_index) in enumerate(stratified_kf.split(loaded_features, loaded_labels)):\n",
    "    X_train, X_test = loaded_features[train_index], loaded_features[test_index]\n",
    "    y_train, y_test = loaded_labels[train_index], loaded_labels[test_index]\n",
    "\n",
    "    # Train the best model on the training data\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]  # Probability of belonging to the positive class\n",
    "\n",
    "    # Calculate and store accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "    # Calculate and store precision, recall, F1 score, and ROC-AUC score\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_score_list.append(f1)\n",
    "    roc_auc_list.append(roc_auc)\n",
    "\n",
    "# Calculate and print average metrics\n",
    "average_accuracy = np.mean(accuracy_list)\n",
    "average_precision = np.mean(precision_list)\n",
    "average_recall = np.mean(recall_list)\n",
    "average_f1_score = np.mean(f1_score_list)\n",
    "average_roc_auc = np.mean(roc_auc_list)\n",
    "\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "print(\"Average Precision:\", average_precision)\n",
    "print(\"Average Recall:\", average_recall)\n",
    "print(\"Average F1 Score:\", average_f1_score)\n",
    "print(\"Average ROC-AUC Score:\", average_roc_auc)\n",
    "\n",
    "# Export metrics to an Excel file\n",
    "metrics_dict = {\n",
    "    \"Fold\": list(range(1, stratified_kf.n_splits + 1)),\n",
    "    \"Accuracy\": accuracy_list,\n",
    "    \"Precision\": precision_list,\n",
    "    \"Recall\": recall_list,\n",
    "    \"F1 Score\": f1_score_list,\n",
    "    \"ROC-AUC Score\": roc_auc_list,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(metrics_dict)\n",
    "df.to_excel(\"svm_metrics_hyperparameter_tuning_new10X.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c1ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE\n",
    "\n",
    "# Load your features and labels\n",
    "features_path = './extracted_features_New_10X.npy'\n",
    "labels_path = './labels_New_10X.npy'\n",
    "\n",
    "loaded_features = np.load(features_path)\n",
    "loaded_labels = np.load(labels_path)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the loaded features\n",
    "loaded_features = scaler.fit_transform(loaded_features)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "model = SVC(kernel='rbf', probability=True, C = 10, gamma = 'scale' )\n",
    "\n",
    "# Initialize arrays to store metrics for each fold\n",
    "cv_accuracies = []\n",
    "cv_precisions = []\n",
    "cv_recalls = []\n",
    "cv_f1_scores = []\n",
    "cv_roc_auc_scores = []\n",
    "\n",
    "# Initialize an array to store the average model coefficients\n",
    "#average_model_coefficients = np.zeros(loaded_features.shape[1])\n",
    "\n",
    "# Stratified Cross-Validation\n",
    "stratified_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Stratified Cross-Validation and calculate metrics\n",
    "for fold, (train_index, test_index) in enumerate(stratified_kf.split(loaded_features, loaded_labels), 1):\n",
    "    X_train, X_test = loaded_features[train_index], loaded_features[test_index]\n",
    "    y_train, y_test = loaded_labels[train_index], loaded_labels[test_index]\n",
    "\n",
    "    # Apply SMOTE to balance the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Print the number of instances for each class in each fold after SMOTE for training set\n",
    "    print(f\"\\nFold {fold} - Training Set (After SMOTE):\")\n",
    "    print(\"Positive Class Instances:\", np.sum(y_train_smote == 1))\n",
    "    print(\"Negative Class Instances:\", np.sum(y_train_smote == 0))\n",
    "\n",
    "    # Train the SVM model on the balanced training data\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Get the coefficients of the support vectors\n",
    "    #coefficients = model.coef_[0]\n",
    "\n",
    "    # Accumulate the coefficients for this fold\n",
    "    #average_model_coefficients += coefficients\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    cv_accuracies.append(accuracy)\n",
    "    cv_precisions.append(precision)\n",
    "    cv_recalls.append(recall)\n",
    "    cv_f1_scores.append(f1)\n",
    "    cv_roc_auc_scores.append(roc_auc)\n",
    "\n",
    "    # Print the number of instances for each class in each fold after SMOTE for testing set\n",
    "    print(f\"\\nFold {fold} - Testing Set (After SMOTE):\")\n",
    "    print(\"Positive Class Instances:\", np.sum(y_test == 1))\n",
    "    print(\"Negative Class Instances:\", np.sum(y_test == 0))\n",
    "\n",
    "# Calculate the average coefficients over all folds\n",
    "#average_model_coefficients /= stratified_kf.n_splits\n",
    "\n",
    "# Print the average coefficients\n",
    "print(\"\\nAverage Model Coefficients:\")\n",
    "#for i, coef in enumerate(average_model_coefficients):\n",
    "#    print(f\"Feature {i+1}: {coef}\")\n",
    "\n",
    "# Print the average metrics over all folds\n",
    "print(\"\\nAverage Metrics:\")\n",
    "print(f\"Average Accuracy: {np.mean(cv_accuracies)}\")\n",
    "print(f\"Average Precision: {np.mean(cv_precisions)}\")\n",
    "print(f\"Average Recall: {np.mean(cv_recalls)}\")\n",
    "print(f\"Average F1 Score: {np.mean(cv_f1_scores)}\")\n",
    "print(f\"Average ROC-AUC: {np.mean(cv_roc_auc_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab703a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the extracted features and labels from the saved files\n",
    "X = np.load('extracted_features_4X_reg.npy')\n",
    "y = np.load('labels_4X_reg.npy')\n",
    "\n",
    "# Initialize the Random Forest Regressor model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Define the number of splits for stratified cross-validation\n",
    "n_splits = 5  # You can adjust this based on your preference\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform stratified cross-validation\n",
    "for i, (train_index, test_index) in enumerate(stratified_kfold.split(X, y)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics for evaluation\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Print metrics for each split\n",
    "    print(f\"\\nSplit {i + 1}:\")\n",
    "    print(\"Mean Absolute Error:\", mae)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"Root Mean Squared Error:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the extracted features and labels from the saved files\n",
    "X = np.load('extracted_features_10X_reg.npy')\n",
    "y = np.load('labels_10X_reg.npy')\n",
    "\n",
    "# Initialize the Random Forest Regressor model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Define the number of splits for stratified cross-validation\n",
    "n_splits = 5  # You can adjust this based on your preference\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform stratified cross-validation\n",
    "for i, (train_index, test_index) in enumerate(stratified_kfold.split(X, y)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics for evaluation\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Print metrics for each split\n",
    "    print(f\"\\nSplit {i + 1}:\")\n",
    "    print(\"Mean Absolute Error:\", mae)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"Root Mean Squared Error:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7fb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
